#!/usr/bin/env python3
import os
import json
import hashlib
import tarfile
import time
import requests
import io
from tqdm import tqdm
# å¯¼å…¥ fileinfo_api å’Œ filemanager_api
from openapi_client.api import fileupload_api, fileinfo_api, filemanager_api
from openapi_client import ApiClient, ApiException

# ==============================================================================
# ===== é…ç½®åŒº (æ‚¨åªéœ€è¦ä¿®æ”¹è¿™é‡Œ) =====
# ==============================================================================

# 1. è¦å¤‡ä»½çš„æœ¬åœ°ç›®å½• (è¯·ä½¿ç”¨ç»å¯¹è·¯å¾„)
LOCAL_DIR = "/path/to/your/data/to/backup"

# 2. è¦ä¸Šä¼ åˆ°çš„ç½‘ç›˜ç›®å½• (å¿…é¡»ä»¥ /apps/ å¼€å¤´)
REMOTE_DIR = "/apps/ä½ çš„åº”ç”¨åç§°/backup_folder"

# 3. æœ€å¤§ä¿ç•™çš„å¤‡ä»½æ–‡ä»¶æ•°é‡
#    - è®¾ç½®ä¸º 7ï¼Œè¡¨ç¤ºæ¯æ¬¡å¤‡ä»½æˆåŠŸåï¼Œç½‘ç›˜é‡Œæœ€å¤šåªä¿ç•™æœ€æ–°çš„ 7 ä¸ªå¤‡ä»½æ–‡ä»¶ã€‚
#    - è®¾ç½®ä¸º 0ï¼Œè¡¨ç¤ºä¸é™åˆ¶æ•°é‡ï¼Œä¿ç•™æ‰€æœ‰å¤‡ä»½ã€‚
MAX_BACKUPS = 7

# ==============================================================================
# ===== ç¨‹åºæ ¸å¿ƒä»£ç  (ä»¥ä¸‹éƒ¨åˆ†æ— éœ€ä¿®æ”¹) =====
# ==============================================================================

# --- ä»ç¯å¢ƒå˜é‡å®‰å…¨åœ°è¯»å–å¯†é’¥ ---
APP_KEY = os.getenv("BAIDU_APP_KEY")
SECRET_KEY = os.getenv("BAIDU_SECRET_KEY")

# --- å…¨å±€å¸¸é‡ ---
REDIRECT_URI = "oob"
TOKEN_FILE = "baidu_token.json"
CHUNK_SIZE = 4 * 1024 * 1024

# ===== Token ç®¡ç† =====
def get_access_token():
    if not all([APP_KEY, SECRET_KEY]):
        print("âŒ é”™è¯¯ï¼šè¯·å…ˆè®¾ç½®ç³»ç»Ÿç¯å¢ƒå˜é‡ BAIDU_APP_KEY å’Œ BAIDU_SECRET_KEY")
        exit(1)
    if os.path.exists(TOKEN_FILE):
        try:
            with open(TOKEN_FILE, "r") as f:
                token_data = json.load(f)
            if time.time() < token_data["expires_at"]:
                print("âœ… ä½¿ç”¨æœ¬åœ° access_token")
                return token_data["access_token"]
            else:
                print("ğŸ”„ access_token å·²è¿‡æœŸï¼Œå°è¯•åˆ·æ–°...")
                refresh_token = token_data.get("refresh_token")
                if refresh_token: return refresh_access_token(refresh_token)
        except (json.JSONDecodeError, KeyError):
            print("âš ï¸ Token æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œå°†é‡æ–°æˆæƒã€‚")
    return authorize_new_token()

def authorize_new_token():
    auth_url = (f"https://openapi.baidu.com/oauth/2.0/authorize?response_type=code&client_id={APP_KEY}"
                f"&redirect_uri={REDIRECT_URI}&scope=basic,netdisk")
    print("\né¦–æ¬¡è¿è¡Œæˆ–æˆæƒå¤±è´¥ï¼Œè¯·åœ¨æµè§ˆå™¨æ‰“å¼€ä»¥ä¸‹é“¾æ¥ï¼Œç™»å½•å¹¶æˆæƒï¼š\n\n" + auth_url)
    code = input("\nè¯·è¾“å…¥æµè§ˆå™¨è¿”å›çš„ code: ").strip()
    token_url = "https://openapi.baidu.com/oauth/2.0/token"
    params = {"grant_type": "authorization_code", "code": code, "client_id": APP_KEY,
              "client_secret": SECRET_KEY, "redirect_uri": REDIRECT_URI}
    resp = requests.get(token_url, params=params)
    resp.raise_for_status()
    data = resp.json()
    if "access_token" in data:
        save_token(data)
        return data["access_token"]
    raise RuntimeError(f"è·å– access_token å¤±è´¥: {data}")

def refresh_access_token(refresh_token):
    token_url = "https://openapi.baidu.com/oauth/2.0/token"
    params = {"grant_type": "refresh_token", "refresh_token": refresh_token,
              "client_id": APP_KEY, "client_secret": SECRET_KEY}
    resp = requests.get(token_url, params=params)
    resp.raise_for_status()
    data = resp.json()
    if "access_token" in data:
        save_token(data)
        return data["access_token"]
    print("âŒ åˆ·æ–° token å¤±è´¥ï¼Œéœ€è¦é‡æ–°æˆæƒ")
    return authorize_new_token()

def save_token(data):
    data["expires_at"] = time.time() + int(data["expires_in"]) - 300
    with open(TOKEN_FILE, "w") as f: json.dump(data, f, indent=4)
    print("ğŸ’¾ å·²ä¿å­˜æ–°çš„ token")

# ===== ä¸Šä¼ ä¸å¤‡ä»½ç®¡ç† =====
def md5_bytes(data):
    return hashlib.md5(data).hexdigest()

def get_block_md5_list(path):
    block_md5_list = []
    with open(path, "rb") as f:
        while True:
            chunk = f.read(CHUNK_SIZE)
            if not chunk: break
            block_md5_list.append(md5_bytes(chunk))
    return block_md5_list

def upload_part(api_instance, access_token, remote_path, uploadid, part_index, local_path):
    for attempt in range(3):
        try:
            with open(local_path, "rb") as fp:
                fp.seek(part_index * CHUNK_SIZE)
                chunk_data = fp.read(CHUNK_SIZE)
                if not chunk_data: break
                with io.BytesIO(chunk_data) as chunk_fp:
                    chunk_fp.name = 'chunk_part_data'
                    api_instance.pcssuperfile2(access_token=access_token, partseq=str(part_index),
                                               path=remote_path, uploadid=uploadid, type="tmpfile",
                                               file=chunk_fp, _request_timeout=300)
            return
        except ApiException as e:
            if 400 <= e.status < 500: raise RuntimeError(f"åˆ†ç‰‡ {part_index} ä¸Šä¼ å¤±è´¥ (å®¢æˆ·ç«¯é”™è¯¯ {e.status})ï¼Œä¸­æ­¢: {e.reason}")
            print(f"âš ï¸ åˆ†ç‰‡ {part_index} ä¸Šä¼ å¤±è´¥ (APIé”™è¯¯)ï¼Œç¬¬ {attempt+1} æ¬¡é‡è¯•: {e.reason}")
            time.sleep(2 ** attempt)
        except Exception as e:
            print(f"âš ï¸ åˆ†ç‰‡ {part_index} ä¸Šä¼ å¤±è´¥ (ç½‘ç»œæˆ–å…¶ä»–é”™è¯¯)ï¼Œç¬¬ {attempt+1} æ¬¡é‡è¯•: {e}")
            time.sleep(2 ** attempt)
    raise RuntimeError(f"âŒ åˆ†ç‰‡ {part_index} ä¸Šä¼ å¤±è´¥ï¼Œå·²é‡è¯• 3 æ¬¡")

def upload_large_file(api_instance, access_token, local_path, remote_path):
    file_size = os.path.getsize(local_path)
    print(f"æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")
    print("â³ æ­£åœ¨è¿›è¡Œé¢„ä¸Šä¼ ...")
    block_md5_list = get_block_md5_list(local_path)
    precreate_resp = api_instance.xpanfileprecreate(access_token=access_token, path=remote_path, size=file_size,
                                                    isdir=0, autoinit=1, block_list=json.dumps(block_md5_list))
    uploadid = precreate_resp.get("uploadid")
    if not uploadid: raise RuntimeError(f"é¢„ä¸Šä¼ å¤±è´¥: {precreate_resp}")
    print(f"âœ… é¢„ä¸Šä¼ æˆåŠŸ, UploadID: {uploadid}")
    print("ğŸš€ å¼€å§‹åˆ†ç‰‡ä¸Šä¼ ...")
    with tqdm(total=len(block_md5_list), unit="part", desc="ä¸Šä¼ è¿›åº¦") as pbar:
        for idx in range(len(block_md5_list)):
            upload_part(api_instance, access_token, remote_path, uploadid, idx, local_path)
            pbar.update(1)
    print("ğŸ¤ æ­£åœ¨åˆå¹¶æ–‡ä»¶...")
    create_resp = api_instance.xpanfilecreate(access_token=access_token, path=remote_path, size=file_size,
                                              isdir=0, uploadid=uploadid, block_list=json.dumps(block_md5_list))
    if 'fs_id' not in create_resp: raise RuntimeError(f"åˆå¹¶æ–‡ä»¶å¤±è´¥: {create_resp}")
    print(f"ğŸ‰ æ–‡ä»¶ä¸Šä¼ æˆåŠŸ! ç½‘ç›˜è·¯å¾„: {create_resp.get('path')}")

def compress_directory(local_dir, output_path):
    print(f"ğŸ“¦ æ­£åœ¨å‹ç¼© {local_dir} -> {output_path}")
    with tarfile.open(output_path, "w:gz") as tar:
        tar.add(local_dir, arcname=os.path.basename(local_dir))
    print("å‹ç¼©å®Œæˆ")

def manage_backups(api_client, access_token, remote_dir, max_backups):
    if max_backups <= 0:
        print("â„¹ï¸  ä¿ç•™æ‰€æœ‰å¤‡ä»½æ–‡ä»¶ï¼ˆMAX_BACKUPS <= 0ï¼‰ã€‚")
        return

    print(f"ğŸ”„ æ­£åœ¨æ£€æŸ¥æ—§å¤‡ä»½ï¼Œå°†åªä¿ç•™æœ€æ–°çš„ {max_backups} ä»½...")
    try:
        info_api = fileinfo_api.FileinfoApi(api_client)
        response = info_api.xpanfilelist(access_token=access_token, dir=remote_dir, order="name", desc=0)
        
        file_list = response.get('list')
        if not file_list:
            print("âš ï¸ æœªèƒ½åœ¨å¤‡ä»½ç›®å½•ä¸­æ‰¾åˆ°ä»»ä½•æ–‡ä»¶æˆ–ç›®å½•ä¸ºç©ºã€‚")
            return

        backup_files = sorted(
            [f for f in file_list if f.get('path', '').endswith('.tar.gz')],
            key=lambda x: x['path']
        )
        
        num_to_delete = len(backup_files) - max_backups
        if num_to_delete <= 0:
            print(f"âœ… å¤‡ä»½æ–‡ä»¶æ•°é‡ ({len(backup_files)}) æœªè¶…é™ï¼Œæ— éœ€æ¸…ç†ã€‚")
            return
            
        print(f"ğŸ—‘ï¸ å‘ç° {len(backup_files)} ä»½å¤‡ä»½ï¼Œéœ€è¦åˆ é™¤æœ€æ—§çš„ {num_to_delete} ä»½ã€‚")
        files_to_delete = [f['path'] for f in backup_files[:num_to_delete]]
        
        manager_api = filemanager_api.FilemanagerApi(api_client)
        
        # ==============================================================================
        # ===== æœ€ç»ˆé”™è¯¯ä¿®æ­£ç‚¹ (async_ -> _async) =====
        # ==============================================================================
        delete_resp = manager_api.filemanagerdelete(access_token=access_token, _async=0, filelist=json.dumps(files_to_delete))

        print("âœ… å·²æˆåŠŸåˆ é™¤æ—§çš„å¤‡ä»½æ–‡ä»¶ï¼š")
        for f_path in files_to_delete:
            print(f"   - {os.path.basename(f_path)}")

    except ApiException as e:
        print(f"âŒ ç®¡ç†å¤‡ä»½æ–‡ä»¶æ—¶å‘ç”ŸAPIé”™è¯¯: {e.reason}")
    except Exception as e:
        print(f"âŒ ç®¡ç†å¤‡ä»½æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

# ===== ä¸»æµç¨‹ =====
if __name__ == "__main__":
    if not os.path.isdir(LOCAL_DIR):
        print(f"âŒ é”™è¯¯: æœ¬åœ°ç›®å½• '{LOCAL_DIR}' ä¸å­˜åœ¨æˆ–ä¸æ˜¯ä¸€ä¸ªç›®å½•ã€‚")
        exit(1)
    
    tar_filename = f"{os.path.basename(LOCAL_DIR.rstrip(os.sep))}_{time.strftime('%Y%m%d-%H%M%S')}.tar.gz"
    local_tar_path = os.path.join(os.path.dirname(LOCAL_DIR.rstrip(os.sep)), tar_filename)

    try:
        access_token = get_access_token()
        compress_directory(LOCAL_DIR, local_tar_path)
        
        with ApiClient() as api_client:
            upload_api_instance = fileupload_api.FileuploadApi(api_client)
            remote_tar_path = os.path.join(REMOTE_DIR, os.path.basename(local_tar_path)).replace("\\", "/")
            
            upload_large_file(upload_api_instance, access_token, local_tar_path, remote_tar_path)
            manage_backups(api_client, access_token, REMOTE_DIR, MAX_BACKUPS)

    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
    finally:
        if 'local_tar_path' in locals() and os.path.exists(local_tar_path):
            print(f"ğŸ§¹ åˆ é™¤æœ¬åœ°ä¸´æ—¶å‹ç¼©æ–‡ä»¶: {local_tar_path}")
            os.remove(local_tar_path)
