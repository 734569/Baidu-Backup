#!/usr/bin/env python3
import os
import json
import hashlib
import tarfile
import time
import requests
import io
import argparse

# å¯¼å…¥ fileinfo_api å’Œ filemanager_api
from openapi_client.api import fileupload_api, fileinfo_api, filemanager_api
from openapi_client import ApiClient, ApiException

# ==============================================================================
# ===== (âœ”) æœ€ç»ˆ Python é…ç½®åŒº - æ— éœ€ä»»ä½•é…ç½®ï¼ =====
# ==============================================================================

# --- ä»ç¯å¢ƒå˜é‡å®‰å…¨åœ°è¯»å–å¯†é’¥ ---
APP_KEY = os.getenv("BAIDU_APP_KEY")
SECRET_KEY = os.getenv("BAIDU_SECRET_KEY")

# --- å…¨å±€å¸¸é‡ ---
REDIRECT_URI = "oob"
CHUNK_SIZE = 4 * 1024 * 1024  # 4MBåˆ†ç‰‡å¤§å°
SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))
TOKEN_FILE = os.path.join(SCRIPT_DIR, "baidu_token.json")

# ===== Token ç®¡ç† (ä¿ç•™ç¯å¢ƒå˜é‡ä¼˜å…ˆé€»è¾‘) =====
def get_access_token():
    # ä¼˜å…ˆè¯»å–ç¯å¢ƒå˜é‡ä»¤ç‰Œ
    env_token = os.getenv("BAIDU_ACCESS_TOKEN")
    if env_token and env_token.strip():
        print("âœ… ä½¿ç”¨ç¯å¢ƒå˜é‡æä¾›çš„ access_token")
        return env_token.strip()
    
    # åŸæœ‰é€»è¾‘ï¼šç¯å¢ƒå˜é‡æ— ä»¤ç‰Œæ—¶æ‰ä½¿ç”¨æœ¬åœ°æ–‡ä»¶æˆ–é‡æ–°æˆæƒ
    if not all([APP_KEY, SECRET_KEY]):
        print("âŒ é”™è¯¯ï¼šè¯·å…ˆè®¾ç½®ç³»ç»Ÿç¯å¢ƒå˜é‡ BAIDU_APP_KEY å’Œ BAIDU_SECRET_KEY")
        exit(1)
    if os.path.exists(TOKEN_FILE):
        try:
            with open(TOKEN_FILE, "r") as f:
                token_data = json.load(f)
            if time.time() < token_data["expires_at"]:
                print("âœ… ä½¿ç”¨æœ¬åœ° access_token")
                return token_data["access_token"]
            else:
                print("ğŸ”„ access_token å·²è¿‡æœŸï¼Œå°è¯•åˆ·æ–°...")
                refresh_token = token_data.get("refresh_token")
                if refresh_token: return refresh_access_token(refresh_token)
        except (json.JSONDecodeError, KeyError):
            print("âš ï¸ Token æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œå°†é‡æ–°æˆæƒã€‚")
    return authorize_new_token()

def authorize_new_token():
    auth_url = (f"https://openapi.baidu.com/oauth/2.0/authorize?response_type=code&client_id={APP_KEY}"
                f"&redirect_uri={REDIRECT_URI}&scope=basic,netdisk")
    print("\né¦–æ¬¡è¿è¡Œæˆ–æˆæƒå¤±è´¥ï¼Œè¯·åœ¨æµè§ˆå™¨æ‰“å¼€ä»¥ä¸‹é“¾æ¥ï¼Œç™»å½•å¹¶æˆæƒï¼š\n\n" + auth_url)
    code = input("\nè¯·è¾“å…¥æµè§ˆå™¨è¿”å›çš„ code: ").strip()
    token_url = "https://openapi.baidu.com/oauth/2.0/token"
    params = {"grant_type": "authorization_code", "code": code, "client_id": APP_KEY,
              "client_secret": SECRET_KEY, "redirect_uri": REDIRECT_URI}
    resp = requests.get(token_url, params=params)
    resp.raise_for_status()
    data = resp.json()
    if "access_token" in data:
        save_token(data)
        return data["access_token"]
    raise RuntimeError(f"è·å– access_token å¤±è´¥: {data}")

def refresh_access_token(refresh_token):
    token_url = "https://openapi.baidu.com/oauth/2.0/token"
    params = {"grant_type": "refresh_token", "refresh_token": refresh_token,
              "client_id": APP_KEY, "client_secret": SECRET_KEY}
    resp = requests.get(token_url, params=params)
    resp.raise_for_status()
    data = resp.json()
    if "access_token" in data:
        save_token(data)
        return data["access_token"]
    print("âŒ åˆ·æ–° token å¤±è´¥ï¼Œéœ€è¦é‡æ–°æˆæƒ")
    return authorize_new_token()

def save_token(data):
    data["expires_at"] = time.time() + int(data["expires_in"]) - 300
    with open(TOKEN_FILE, "w") as f: json.dump(data, f, indent=4)
    print("ğŸ’¾ å·²ä¿å­˜æ–°çš„ token")

# ===== ä¸Šä¼ ä¸å¤‡ä»½ç®¡ç† (ç§»é™¤é¢„é£è¡Œè‡ªæ£€) =====
def md5_bytes(data):
    return hashlib.md5(data).hexdigest()

# ä¼˜åŒ–ï¼šåªè¯»å–ä¸€æ¬¡æ–‡ä»¶è®¡ç®—MD5ï¼Œæé«˜æ•ˆç‡
def get_block_md5_list(path):
    block_md5_list = []
    with open(path, "rb") as f:
        while True:
            chunk = f.read(CHUNK_SIZE)
            if not chunk: break
            block_md5_list.append(md5_bytes(chunk))
    return block_md5_list
    
def upload_part(api_instance, access_token, remote_path, uploadid, part_index, local_path):
    for attempt in range(3):
        try:
            with open(local_path, "rb") as fp:
                fp.seek(part_index * CHUNK_SIZE)
                chunk_data = fp.read(CHUNK_SIZE)
                if not chunk_data: break
                with io.BytesIO(chunk_data) as chunk_fp:
                    chunk_fp.name = 'chunk_part_data'
                    api_instance.pcssuperfile2(access_token=access_token, partseq=str(part_index),
                                               path=remote_path, uploadid=uploadid, type="tmpfile",
                                               file=chunk_fp, _request_timeout=300)
            return
        except ApiException as e:
            if 400 <= e.status < 500: raise RuntimeError(f"åˆ†ç‰‡ {part_index + 1} ä¸Šä¼ å¤±è´¥ (å®¢æˆ·ç«¯é”™è¯¯ {e.status})ï¼Œä¸­æ­¢: {e.reason}")
            print(f"âš ï¸ åˆ†ç‰‡ {part_index + 1} ä¸Šä¼ å¤±è´¥ (APIé”™è¯¯)ï¼Œç¬¬ {attempt+1} æ¬¡é‡è¯•: {e.reason}")
            time.sleep(2 ** attempt)
        except Exception as e:
            print(f"âš ï¸ åˆ†ç‰‡ {part_index + 1} ä¸Šä¼ å¤±è´¥ (ç½‘ç»œæˆ–å…¶ä»–é”™è¯¯)ï¼Œç¬¬ {attempt+1} æ¬¡é‡è¯•: {e}")
            time.sleep(2 ** attempt)
    raise RuntimeError(f"âŒ åˆ†ç‰‡ {part_index + 1} ä¸Šä¼ å¤±è´¥ï¼Œå·²é‡è¯• 3 æ¬¡")

def upload_large_file(api_instance, access_token, local_path, remote_path):
    file_size = os.path.getsize(local_path)
    print(f"æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")
    
    # ã€ç§»é™¤é¢„é£è¡Œè‡ªæ£€ã€‘ç›´æ¥è®¡ç®—ä¸€æ¬¡MD5
    print("ğŸ”¬ è®¡ç®—æ–‡ä»¶æ ¡éªŒä¿¡æ¯...")
    block_md5_list = get_block_md5_list(local_path)
    total_parts = len(block_md5_list)
    print(f"âœ… æ–‡ä»¶æ ¡éªŒä¿¡æ¯è®¡ç®—å®Œæˆï¼Œå…± {total_parts} ä¸ªåˆ†ç‰‡ã€‚")

    print("â³ æ­£åœ¨è¿›è¡Œé¢„ä¸Šä¼ ...")
    precreate_resp = api_instance.xpanfileprecreate(
        access_token=access_token, path=remote_path, size=file_size,
        isdir=0, autoinit=1, block_list=json.dumps(block_md5_list)
    )
    uploadid = precreate_resp.get("uploadid")
    if not uploadid: raise RuntimeError(f"é¢„ä¸Šä¼ å¤±è´¥: {precreate_resp}")
    print(f"âœ… é¢„ä¸Šä¼ æˆåŠŸ, UploadID: {uploadid}")

    print("ğŸš€ å¼€å§‹åˆ†ç‰‡ä¸Šä¼ ...")
    for idx in range(total_parts):
        upload_part(api_instance, access_token, remote_path, uploadid, idx, local_path)
    print("  > æ‰€æœ‰åˆ†ç‰‡ä¸Šä¼ å®Œæ¯•ã€‚")

    print("ğŸ¤ æ­£åœ¨åˆå¹¶æ–‡ä»¶...")
    create_resp = api_instance.xpanfilecreate(
        access_token=access_token, path=remote_path, size=file_size,
        isdir=0, uploadid=uploadid, block_list=json.dumps(block_md5_list)
    )
    if 'fs_id' not in create_resp: raise RuntimeError(f"åˆå¹¶æ–‡ä»¶å¤±è´¥: {create_resp}")
    print(f"ğŸ‰ æ–‡ä»¶ä¸Šä¼ æˆåŠŸ! ç½‘ç›˜è·¯å¾„: {create_resp.get('path')}")

def manage_backups(api_client, access_token, remote_dir, max_backups):
    if max_backups <= 0:
        print("â„¹ï¸  ä¿ç•™æ‰€æœ‰å¤‡ä»½æ–‡ä»¶ï¼ˆMAX_BACKUPS <= 0ï¼‰ã€‚")
        return

    print(f"ğŸ”„ æ­£åœ¨æ£€æŸ¥æ—§å¤‡ä»½ï¼Œå°†åªä¿ç•™æœ€æ–°çš„ {max_backups} ä»½...")
    try:
        info_api = fileinfo_api.FileinfoApi(api_client)
        response = info_api.xpanfilelist(access_token=access_token, dir=remote_dir)
        
        file_list = response.get('list')
        if not file_list:
            print("âš ï¸ æœªèƒ½åœ¨å¤‡ä»½ç›®å½•ä¸­æ‰¾åˆ°ä»»ä½•æ–‡ä»¶æˆ–ç›®å½•ä¸ºç©ºã€‚")
            return

        backup_groups = {}
        for f in file_list:
            path = f.get('path', '')
            base_name = '.'.join(os.path.basename(path).split('.')[:-1])
            if not base_name.endswith('.tar.gz'):
                base_name = os.path.basename(path)
            if base_name not in backup_groups:
                backup_groups[base_name] = []
            backup_groups[base_name].append(path)

        sorted_groups = sorted(backup_groups.keys())
        num_groups = len(sorted_groups)
        num_to_delete = num_groups - max_backups
        
        if num_to_delete <= 0:
            print(f"âœ… å¤‡ä»½ç»„æ•°é‡ ({num_groups}) æœªè¶…é™ï¼Œæ— éœ€æ¸…ç†ã€‚")
            return
            
        print(f"ğŸ—‘ï¸ å‘ç° {num_groups} ä¸ªå¤‡ä»½ç»„ï¼Œéœ€è¦åˆ é™¤æœ€æ—§çš„ {num_to_delete} ä¸ªç»„ã€‚")
        files_to_delete = []
        groups_to_delete = sorted_groups[:num_to_delete]
        
        for group_name in groups_to_delete:
            files_to_delete.extend(backup_groups[group_name])
        
        if not files_to_delete: return
            
        manager_api = filemanager_api.FilemanagerApi(api_client)
        delete_resp = manager_api.filemanagerdelete(access_token=access_token, _async=0, filelist=json.dumps(files_to_delete))

        print("âœ… å·²æˆåŠŸåˆ é™¤æ—§çš„å¤‡ä»½æ–‡ä»¶/ç»„ï¼š")
        for group_name in groups_to_delete:
            print(f"   - {group_name} (åŠæ‰€æœ‰åˆ†å·)")

    except ApiException as e:
        print(f"âŒ ç®¡ç†å¤‡ä»½æ–‡ä»¶æ—¶å‘ç”ŸAPIé”™è¯¯: {e.reason}")
    except Exception as e:
        print(f"âŒ ç®¡ç†å¤‡ä»½æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

# ===== ä¸»æµç¨‹ =====
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Uploads a file to Baidu Netdisk and manages backups.")
    parser.add_argument("--tar-path", required=True, help="The absolute path to the file/volume to be uploaded.")
    parser.add_argument("--remote-dir", required=True, help="The target directory in Baidu Netdisk (must start with /apps/).")
    parser.add_argument("--max-backups", required=True, type=int, help="Maximum number of backup sets to keep (0 for unlimited).")
    args = parser.parse_args()

    local_tar_path = args.tar_path
    remote_dir = args.remote_dir
    max_backups = args.max_backups

    if not os.path.isfile(local_tar_path):
        print(f"âŒ é”™è¯¯: Shellè„šæœ¬æä¾›çš„æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨: '{local_tar_path}'")
        exit(1)

    try:
        access_token = get_access_token()
        with ApiClient() as api_client:
            upload_api_instance = fileupload_api.FileuploadApi(api_client)
            remote_tar_path = os.path.join(remote_dir, os.path.basename(local_tar_path)).replace("\\", "/")
            
            upload_large_file(upload_api_instance, access_token, local_tar_path, remote_tar_path)
            manage_backups(api_client, access_token, remote_dir, max_backups)
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        exit(1)
