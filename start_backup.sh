#!/bin/bash

# ==============================================================================
# ===== (âœ”) æœ€ç»ˆé«˜æ€§èƒ½é…ç½® - æ‰€æœ‰é…ç½®é¡¹é›†ä¸­äºŽæ­¤ï¼ =====
# ==============================================================================

# --- è¯·åœ¨è¿™é‡Œé…ç½®æ‚¨çš„æ‰€æœ‰ä¿¡æ¯ ---
# 1. ç™¾åº¦å¼€æ”¾å¹³å°å‡­è¯
export BAIDU_APP_KEY="ä½ çš„AppKey"
export BAIDU_SECRET_KEY="ä½ çš„SecretKey"

# 2. æœ¬åœ°å¤‡ä»½æºç›®å½•
LIVE_DATA_DIR="/opt"

# 3. äº‘ç«¯å¤‡ä»½ç›®æ ‡ç›®å½•
REMOTE_DIR="/apps/ä½ çš„åº”ç”¨åç§°/server_backups"

# 4. æœ€å¤§ä¿ç•™çš„å¤‡ä»½ç»„æ•°é‡ (è®¾ç½®ä¸º 0 åˆ™ä¿ç•™æ‰€æœ‰)
MAX_BACKUPS=7

# 5. åˆ†å·å¤§å°
SPLIT_SIZE="1G"

# ==============================================================================
# ===== (ðŸš€) æ€§èƒ½ä¼˜åŒ–é…ç½® =====
# ==============================================================================
# 6. å¹¶è¡Œä¸Šä¼ ä»»åŠ¡æ•°
#    - è¿™ä¸ªå€¼å†³å®šäº†åŒæ—¶ä¸Šä¼ å‡ ä¸ªåˆ†å·ã€‚
#    - å»ºè®®ä»Ž 2 æˆ– 3 å¼€å§‹å°è¯•ã€‚å¦‚æžœæ‚¨çš„æœåŠ¡å™¨CPUå’Œå¸¦å®½éƒ½éžå¸¸å……è£•ï¼Œå¯ä»¥é€‚å½“è°ƒé«˜ã€‚
#    - ä¸å»ºè®®è¶…è¿‡æ‚¨æœåŠ¡å™¨çš„ CPU æ ¸å¿ƒæ•°ã€‚
PARALLEL_UPLOADS=3
# ==============================================================================

# 7. Python è§£é‡Šå™¨å’Œè„šæœ¬çš„ç»å¯¹è·¯å¾„
PYTHON_EXECUTABLE="/usr/bin/python3"
BACKUP_SCRIPT_PATH="/path/to/your/Baidu-Backup/Baidu-Backup.py"
# --- é…ç½®ç»“æŸ ---


# ==============================================================================
# ===== ä¸»å¤‡ä»½æµç¨‹ (æ— éœ€ä¿®æ”¹) =====
# ==============================================================================
echo "=========================================================="
echo "Baidu Backup Job (High-Performance Parallel Version) started at $(date)"
echo "=========================================================="

# 1. å‡†å¤‡ç›®å½•å’Œæ–‡ä»¶å
TIMESTAMP=$(date +'%Y%m%d-%H%M%S')
TAR_FILENAME_BASE="$(basename "$LIVE_DATA_DIR")_$TIMESTAMP.tar.gz"
SPLIT_DIR="$(dirname "$LIVE_DATA_DIR")/split_volumes_$TIMESTAMP"
mkdir -p "$SPLIT_DIR"

# 2. ä½¿ç”¨ç®¡é“è¿›è¡Œæµå¼åŽ‹ç¼©å’Œåˆ†å·
echo "--> Step 1: Compressing and splitting on-the-fly..."
tar --ignore-failed-read -czf - -C "$(dirname "$LIVE_DATA_DIR")" "$(basename "$LIVE_DATA_DIR")" | split -b "$SPLIT_SIZE" -d - "$SPLIT_DIR/$TAR_FILENAME_BASE."

if [ -z "$(ls -A "$SPLIT_DIR")" ]; then
    echo "!! FATAL: Streaming process failed. No volumes were created. Aborting."
    rm -rf "$SPLIT_DIR"
    exit 1
fi
echo "--> Streaming process completed."

# ==============================================================================
# ===== æ ¸å¿ƒå‡çº§ç‚¹ï¼šä½¿ç”¨ xargs è¿›è¡Œå¹¶è¡Œä¸Šä¼  =====
# ==============================================================================
# 3. å¹¶è¡Œä¸Šä¼ æ¯ä¸€ä¸ªå°åˆ†å·
echo "--> Step 2: Uploading volumes in parallel (max ${PARALLEL_UPLOADS} jobs)..."
# åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ—¥å¿—æ–‡ä»¶æ¥æ•èŽ·æ‰€æœ‰å¹¶è¡Œä»»åŠ¡çš„è¾“å‡º
LOG_FILE="${SPLIT_DIR}/parallel_upload.log"

# ls -1: åˆ—å‡ºæ‰€æœ‰åˆ†å·æ–‡ä»¶å
# xargs -P: æŒ‡å®šæœ€å¤§å¹¶è¡Œè¿›ç¨‹æ•°
# xargs -I {}: å°†æ¯ä¸ªæ–‡ä»¶åèµ‹å€¼ç»™å ä½ç¬¦ {}
# bash -c '...': å¯åŠ¨ä¸€ä¸ªç‹¬ç«‹çš„ shell æ¥æ‰§è¡Œæˆ‘ä»¬çš„å¤æ‚å‘½ä»¤
ls -1 "$SPLIT_DIR" | xargs -P "$PARALLEL_UPLOADS" -I {} bash -c \
"echo '--- Starting upload for {} ---' && \
cd '$(dirname "$BACKUP_SCRIPT_PATH")' && \
'$PYTHON_EXECUTABLE' '$BACKUP_SCRIPT_PATH' \
    --tar-path '$SPLIT_DIR/{}' \
    --remote-dir '$REMOTE_DIR' \
    --max-backups '$MAX_BACKUPS' && \
echo '--- Finished upload for {} ---'" >> "$LOG_FILE" 2>&1

# æ£€æŸ¥ä¸´æ—¶æ—¥å¿—ä¸­æ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯
if grep -q -e "âŒ" -e "ERROR" -e "FATAL" "$LOG_FILE"; then
    OVERALL_SUCCESS=false
else
    OVERALL_SUCCESS=true
fi
# æ‰“å°æ‰€æœ‰å¹¶è¡Œä»»åŠ¡çš„æ—¥å¿—
echo "--- Parallel Upload Log Start ---"
cat "$LOG_FILE"
echo "--- Parallel Upload Log End ---"
# ==============================================================================


# 4. æœ€ç»ˆæ¸…ç†
echo "--> Step 3: Cleaning up..."
rm -rf "$SPLIT_DIR"
echo "--> Temporary split volumes deleted."

echo "=========================================================="
if [ "$OVERALL_SUCCESS" = true ]; then
    echo "Baidu Backup Job finished successfully at $(date)"
    exit 0
else
    echo "!! Baidu Backup Job finished with at least one ERROR at $(date)"
    exit 1
fi
